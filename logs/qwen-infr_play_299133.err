/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=927881)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=927881)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [01:57<01:57, 117.80s/it]
[0;36m(EngineCore_DP0 pid=927881)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [03:25<00:00, 100.02s/it]
[0;36m(EngineCore_DP0 pid=927881)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [03:25<00:00, 102.68s/it]
[0;36m(EngineCore_DP0 pid=927881)[0;0m 
[0;36m(EngineCore_DP0 pid=927881)[0;0m [rank0]:W1222 18:52:17.058000 927881 site-packages/torch/_inductor/utils.py:1558] Not enough SMs to use max_autotune_gemm mode
[0;36m(EngineCore_DP0 pid=927881)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:27,  1.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 2/51 [00:00<00:14,  3.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 3/51 [00:00<00:10,  4.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–‰         | 5/51 [00:00<00:06,  6.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–Ž        | 7/51 [00:01<00:05,  8.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 9/51 [00:01<00:04,  8.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 11/51 [00:01<00:04,  9.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 13/51 [00:01<00:03, 10.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–‰       | 15/51 [00:01<00:03, 11.25it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 17/51 [00:01<00:02, 12.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/51 [00:02<00:02, 13.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/51 [00:02<00:02, 13.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/51 [00:02<00:01, 14.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25/51 [00:02<00:01, 14.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 27/51 [00:02<00:01, 15.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/51 [00:02<00:01, 16.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 31/51 [00:02<00:01, 17.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 33/51 [00:02<00:01, 17.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 36/51 [00:03<00:00, 19.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 39/51 [00:03<00:00, 16.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/51 [00:03<00:00, 17.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 45/51 [00:03<00:00, 19.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 48/51 [00:03<00:00, 21.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:04<00:00, 11.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:04<00:00, 12.12it/s]
[0;36m(EngineCore_DP0 pid=927881)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   3%|â–Ž         | 1/35 [00:00<00:18,  1.86it/s]Capturing CUDA graphs (decode, FULL):   9%|â–Š         | 3/35 [00:00<00:05,  5.34it/s]Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 5/35 [00:00<00:03,  8.09it/s]Capturing CUDA graphs (decode, FULL):  20%|â–ˆâ–ˆ        | 7/35 [00:00<00:02, 10.21it/s]Capturing CUDA graphs (decode, FULL):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:01<00:02, 11.91it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:01<00:01, 13.60it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:01<00:01, 15.01it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:01<00:01, 16.06it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:01<00:00, 18.08it/s]Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:01<00:00, 20.23it/s]Capturing CUDA graphs (decode, FULL):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:01<00:00, 21.50it/s]Capturing CUDA graphs (decode, FULL):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:01<00:00, 22.59it/s]Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:01<00:00, 23.96it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:02<00:00, 25.25it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 16.34it/s]
Traceback (most recent call last):
  File "/home/ADV_2526a/evyataroren/inter_2025/play/check_abillity_to_recover.py", line 510, in <module>
    run_prompt_injection_experiment()
  File "/home/ADV_2526a/evyataroren/inter_2025/play/check_abillity_to_recover.py", line 396, in run_prompt_injection_experiment
    full_generation, injection_point, pre_injection_text = generate_with_injection(
                                                           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ADV_2526a/evyataroren/inter_2025/play/check_abillity_to_recover.py", line 190, in generate_with_injection
    outputs = llm.generate(
              ^^^^^^^^^^^^^
TypeError: LLM.generate() got an unexpected keyword argument 'prompt_token_ids'
