Mon Dec 22 11:26:10 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA RTX A5000               On  |   00000000:01:00.0 Off |                  Off |
| 50%   76C    P2            228W /  230W |   17995MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA RTX A5000               On  |   00000000:21:00.0 Off |                  Off |
| 30%   56C    P2            128W /  230W |   17415MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA RTX A5000               On  |   00000000:41:00.0 Off |                  Off |
| 30%   45C    P2            130W /  230W |   17415MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA RTX A5000               On  |   00000000:61:00.0 Off |                  Off |
| 30%   49C    P2            138W /  230W |   17415MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA RTX A5000               On  |   00000000:81:00.0 Off |                  Off |
| 30%   39C    P2            130W /  230W |   17415MiB /  24564MiB |    100%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA RTX A5000               On  |   00000000:A1:00.0 Off |                  Off |
| 30%   40C    P2            109W /  230W |   18707MiB /  24564MiB |     31%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA RTX A5000               On  |   00000000:C1:00.0 Off |                  Off |
| 30%   42C    P2            144W /  230W |   14449MiB /  24564MiB |     58%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA RTX A5000               On  |   00000000:E1:00.0 Off |                  Off |
| 30%   26C    P5             30W /  230W |       2MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   1216959      C   python                                      17988MiB |
|    1   N/A  N/A   1258511      C   ...sler/miniconda3/envs/dev/bin/python      17408MiB |
|    2   N/A  N/A   1258512      C   ...sler/miniconda3/envs/dev/bin/python      17408MiB |
|    3   N/A  N/A   1258513      C   ...sler/miniconda3/envs/dev/bin/python      17408MiB |
|    4   N/A  N/A   1258514      C   ...sler/miniconda3/envs/dev/bin/python      17408MiB |
|    5   N/A  N/A   1227889      C   ...s/almogt/sampled-kd/venv/bin/python      18700MiB |
|    6   N/A  N/A   1227889      C   ...s/almogt/sampled-kd/venv/bin/python      14442MiB |
+-----------------------------------------------------------------------------------------+
Looking in indexes: https://download.pytorch.org/whl/cu124
Collecting torch
  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)
Collecting filelock (from torch)
  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions>=4.10.0 (from torch)
  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting networkx (from torch)
  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)
Collecting jinja2 (from torch)
  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch)
  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
Collecting nvidia-curand-cu12==10.3.5.147 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting nvidia-nccl-cu12==2.21.5 (from torch)
  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
Collecting nvidia-nvtx-cu12==12.4.127 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)
  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
Collecting triton==3.2.0 (from torch)
  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)
Collecting sympy==1.13.1 (from torch)
  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch)
  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)
Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)
Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)
Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 13.8 MB/s  0:00:00
Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Using cached filelock-3.20.0-py3-none-any.whl (16 kB)
Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)
Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)
Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch

Successfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0+cu124 triton-3.2.0 typing-extensions-4.15.0
Collecting transformers
  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)
Collecting vllm
  Using cached vllm-0.13.0-cp38-abi3-manylinux_2_31_x86_64.whl.metadata (18 kB)
Requirement already satisfied: filelock in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from transformers) (3.20.0)
Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)
  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
Collecting numpy>=1.17 (from transformers)
  Using cached numpy-2.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)
Collecting packaging>=20.0 (from transformers)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting pyyaml>=5.1 (from transformers)
  Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting regex!=2019.12.17 (from transformers)
  Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
Collecting requests (from transformers)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)
  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting safetensors>=0.4.3 (from transformers)
  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting tqdm>=4.27 (from transformers)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Requirement already satisfied: fsspec>=2023.5.0 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)
Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)
  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Collecting cachetools (from vllm)
  Using cached cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)
Collecting psutil (from vllm)
  Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)
Collecting sentencepiece (from vllm)
  Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
Collecting blake3 (from vllm)
  Using cached blake3-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)
Collecting py-cpuinfo (from vllm)
  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Collecting protobuf (from vllm)
  Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)
  Downloading fastapi-0.127.0-py3-none-any.whl.metadata (30 kB)
Collecting aiohttp (from vllm)
  Using cached aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
Collecting openai>=1.99.1 (from vllm)
  Using cached openai-2.14.0-py3-none-any.whl.metadata (29 kB)
Collecting pydantic>=2.12.0 (from vllm)
  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)
Collecting prometheus_client>=0.18.0 (from vllm)
  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)
Collecting pillow (from vllm)
  Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)
  Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)
Collecting tiktoken>=0.6.0 (from vllm)
  Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
Collecting lm-format-enforcer==0.11.3 (from vllm)
  Using cached lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)
Collecting llguidance<1.4.0,>=1.3.0 (from vllm)
  Using cached llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting outlines_core==0.2.11 (from vllm)
  Using cached outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting diskcache==5.6.3 (from vllm)
  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
Collecting lark==1.2.2 (from vllm)
  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)
Collecting xgrammar==0.1.27 (from vllm)
  Using cached xgrammar-0.1.27-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting partial-json-parser (from vllm)
  Using cached partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)
Collecting pyzmq>=25.0.0 (from vllm)
  Using cached pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)
Collecting msgspec (from vllm)
  Using cached msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)
Collecting gguf>=0.17.0 (from vllm)
  Using cached gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)
Collecting mistral_common>=1.8.5 (from mistral_common[image]>=1.8.5->vllm)
  Using cached mistral_common-1.8.6-py3-none-any.whl.metadata (5.3 kB)
Collecting opencv-python-headless>=4.11.0 (from vllm)
  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)
Collecting einops (from vllm)
  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)
Collecting compressed-tensors==0.12.2 (from vllm)
  Using cached compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)
Collecting depyf==0.20.0 (from vllm)
  Using cached depyf-0.20.0-py3-none-any.whl.metadata (7.3 kB)
Collecting cloudpickle (from vllm)
  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)
Collecting watchfiles (from vllm)
  Using cached watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Collecting python-json-logger (from vllm)
  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)
Collecting scipy (from vllm)
  Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)
Collecting ninja (from vllm)
  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
Collecting pybase64 (from vllm)
  Using cached pybase64-1.4.3-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)
Collecting cbor2 (from vllm)
  Using cached cbor2-5.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)
Collecting ijson (from vllm)
  Using cached ijson-3.4.0.post0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)
Collecting setproctitle (from vllm)
  Using cached setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)
Collecting openai-harmony>=0.0.3 (from vllm)
  Using cached openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)
Collecting anthropic==0.71.0 (from vllm)
  Using cached anthropic-0.71.0-py3-none-any.whl.metadata (28 kB)
Collecting model-hosting-container-standards<1.0.0,>=0.1.9 (from vllm)
  Using cached model_hosting_container_standards-0.1.12-py3-none-any.whl.metadata (24 kB)
Collecting mcp (from vllm)
  Using cached mcp-1.25.0-py3-none-any.whl.metadata (89 kB)
Collecting numba==0.61.2 (from vllm)
  Using cached numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)
Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)
  Using cached ray-2.53.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (22 kB)
Collecting torch==2.9.0 (from vllm)
  Using cached torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
Collecting torchaudio==2.9.0 (from vllm)
  Using cached torchaudio-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.9 kB)
Collecting torchvision==0.24.0 (from vllm)
  Using cached torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)
Collecting flashinfer-python==0.5.3 (from vllm)
  Using cached flashinfer_python-0.5.3-py3-none-any.whl.metadata (11 kB)
Collecting anyio<5,>=3.5.0 (from anthropic==0.71.0->vllm)
  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)
Collecting distro<2,>=1.7.0 (from anthropic==0.71.0->vllm)
  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
Collecting docstring-parser<1,>=0.15 (from anthropic==0.71.0->vllm)
  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)
Collecting httpx<1,>=0.25.0 (from anthropic==0.71.0->vllm)
  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
Collecting jiter<1,>=0.4.0 (from anthropic==0.71.0->vllm)
  Using cached jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
Collecting sniffio (from anthropic==0.71.0->vllm)
  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
Collecting loguru (from compressed-tensors==0.12.2->vllm)
  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)
Collecting astor (from depyf==0.20.0->vllm)
  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)
Collecting dill (from depyf==0.20.0->vllm)
  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)
Collecting apache-tvm-ffi<0.2,>=0.1 (from flashinfer-python==0.5.3->vllm)
  Using cached apache_tvm_ffi-0.1.6-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)
Collecting click (from flashinfer-python==0.5.3->vllm)
  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
Collecting nvidia-cudnn-frontend>=1.13.0 (from flashinfer-python==0.5.3->vllm)
  Using cached nvidia_cudnn_frontend-1.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)
Collecting nvidia-cutlass-dsl>=4.2.1 (from flashinfer-python==0.5.3->vllm)
  Using cached nvidia_cutlass_dsl-4.3.4-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)
Collecting nvidia-ml-py (from flashinfer-python==0.5.3->vllm)
  Using cached nvidia_ml_py-13.590.44-py3-none-any.whl.metadata (9.8 kB)
Collecting tabulate (from flashinfer-python==0.5.3->vllm)
  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)
  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)
Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)
  Using cached llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)
Collecting numpy>=1.17 (from transformers)
  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
Collecting sympy>=1.13.3 (from torch==2.9.0->vllm)
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: networkx>=2.5.1 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from torch==2.9.0->vllm) (3.6.1)
Requirement already satisfied: jinja2 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from torch==2.9.0->vllm) (3.1.6)
Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.0->vllm)
  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.0->vllm)
  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.0->vllm)
  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.9.0->vllm)
  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.0->vllm)
  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.0->vllm)
  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.0->vllm)
  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.0->vllm)
  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.0->vllm)
  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.9.0->vllm)
  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)
Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.0->vllm)
  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.0->vllm)
  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)
Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.0->vllm)
  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.0->vllm)
  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.0->vllm)
  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
Collecting triton==3.5.0 (from torch==2.9.0->vllm)
  Using cached triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
Collecting idna>=2.8 (from anyio<5,>=3.5.0->anthropic==0.71.0->vllm)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting certifi (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm)
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting httpcore==1.* (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm)
  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm)
  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
Collecting jmespath (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)
  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)
Requirement already satisfied: setuptools in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm) (80.9.0)
Collecting starlette>=0.49.1 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)
  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)
Collecting supervisor>=4.2.0 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)
  Using cached supervisor-4.3.0-py2.py3-none-any.whl.metadata (87 kB)
Collecting annotated-types>=0.6.0 (from pydantic>=2.12.0->vllm)
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.41.5 (from pydantic>=2.12.0->vllm)
  Using cached pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
Collecting typing-inspection>=0.4.2 (from pydantic>=2.12.0->vllm)
  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)
Collecting annotated-doc>=0.0.2 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)
  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)
Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached fastapi_cli-0.0.16-py3-none-any.whl.metadata (6.4 kB)
Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)
  Using cached python_multipart-0.0.21-py3-none-any.whl.metadata (1.8 kB)
Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)
  Using cached email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)
Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)
Collecting pydantic-settings>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)
  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)
Collecting pydantic-extra-types>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)
  Using cached pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)
Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)
  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)
Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached typer-0.20.1-py3-none-any.whl.metadata (16 kB)
Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached rich_toolkit-0.17.1-py3-none-any.whl.metadata (1.0 kB)
Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached fastapi_cloud_cli-0.7.0-py3-none-any.whl.metadata (3.2 kB)
Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached rignore-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)
Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached sentry_sdk-2.48.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting fastar>=0.8.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached fastar-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
Requirement already satisfied: MarkupSafe>=2.0 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from jinja2->torch==2.9.0->vllm) (2.1.5)
Collecting jsonschema>=4.21.1 (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)
Collecting attrs>=22.2.0 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)
Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)
Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached rpds_py-0.30.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting cuda-python>=12.8 (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)
  Using cached cuda_python-13.1.1-py3-none-any.whl.metadata (6.2 kB)
Collecting cuda-bindings~=13.1.1 (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)
  Using cached cuda_bindings-13.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.3 kB)
Collecting cuda-pathfinder~=1.1 (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)
  Using cached cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)
Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)
  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)
Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[standard]>=0.115.0->vllm)
  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)
Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)
  Using cached msgpack-1.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm)
  Using cached cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.4 kB)
Collecting charset_normalizer<4,>=2 (from requests->transformers)
  Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
Collecting urllib3<3,>=1.21.1 (from requests->transformers)
  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)
Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)
Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.9.0->vllm) (1.3.0)
Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)
Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)
Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == "standard"->fastapi[standard]>=0.115.0->vllm)
  Using cached websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->vllm)
  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.4.0 (from aiohttp->vllm)
  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->vllm)
  Using cached frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->vllm)
  Using cached multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp->vllm)
  Using cached propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm)
  Using cached yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm)
  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)
Collecting httpx-sse>=0.4 (from mcp->vllm)
  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)
Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->mcp->vllm)
  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)
Collecting sse-starlette>=1.6.1 (from mcp->vllm)
  Using cached sse_starlette-3.0.4-py3-none-any.whl.metadata (12 kB)
Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.1->mcp->vllm)
  Using cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)
Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm)
  Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm)
  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)
Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Using cached vllm-0.13.0-cp38-abi3-manylinux_2_31_x86_64.whl (474.9 MB)
Using cached anthropic-0.71.0-py3-none-any.whl (355 kB)
Using cached compressed_tensors-0.12.2-py3-none-any.whl (183 kB)
Using cached depyf-0.20.0-py3-none-any.whl (39 kB)
Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)
Using cached flashinfer_python-0.5.3-py3-none-any.whl (7.0 MB)
Using cached lark-1.2.2-py3-none-any.whl (111 kB)
Using cached lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)
Using cached numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)
Using cached outlines_core-0.2.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
Using cached torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)
Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)
Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)
Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)
Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)
Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)
Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)
Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)
Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)
Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)
Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)
Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)
Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
Using cached torchaudio-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.1 MB)
Using cached torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)
Using cached triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)
Using cached xgrammar-0.1.27-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)
Using cached anyio-4.12.0-py3-none-any.whl (113 kB)
Using cached apache_tvm_ffi-0.1.6-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)
Using cached distro-1.9.0-py3-none-any.whl (20 kB)
Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)
Using cached httpx-0.28.1-py3-none-any.whl (73 kB)
Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)
Using cached jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)
Using cached llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Using cached llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)
Using cached model_hosting_container_standards-0.1.12-py3-none-any.whl (105 kB)
Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)
Using cached pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Downloading fastapi-0.127.0-py3-none-any.whl (112 kB)
Using cached starlette-0.50.0-py3-none-any.whl (74 kB)
Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)
Using cached email_validator-2.3.0-py3-none-any.whl (35 kB)
Using cached dnspython-2.8.0-py3-none-any.whl (331 kB)
Using cached fastapi_cli-0.0.16-py3-none-any.whl (12 kB)
Using cached fastapi_cloud_cli-0.7.0-py3-none-any.whl (23 kB)
Using cached fastar-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)
Using cached gguf-0.17.1-py3-none-any.whl (96 kB)
Using cached h11-0.16.0-py3-none-any.whl (37 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached interegular-0.3.3-py37-none-any.whl (23 kB)
Using cached mistral_common-1.8.6-py3-none-any.whl (6.5 MB)
Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)
Using cached attrs-25.4.0-py3-none-any.whl (67 kB)
Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)
Using cached nvidia_cudnn_frontend-1.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)
Using cached nvidia_cutlass_dsl-4.3.4-cp311-cp311-manylinux_2_28_x86_64.whl (58.6 MB)
Using cached cuda_python-13.1.1-py3-none-any.whl (8.0 kB)
Using cached cuda_bindings-13.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (16.3 MB)
Using cached cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)
Using cached openai-2.14.0-py3-none-any.whl (1.1 MB)
Using cached openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Using cached pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)
Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)
Using cached pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)
Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)
Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)
Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)
Using cached python_multipart-0.0.21-py3-none-any.whl (24 kB)
Using cached pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)
Using cached pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (857 kB)
Using cached ray-2.53.0-cp311-cp311-manylinux2014_x86_64.whl (72.3 MB)
Using cached msgpack-1.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (426 kB)
Using cached click-8.3.1-py3-none-any.whl (108 kB)
Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)
Using cached referencing-0.37.0-py3-none-any.whl (26 kB)
Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)
Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached rich_toolkit-0.17.1-py3-none-any.whl (31 kB)
Using cached rich-14.2.0-py3-none-any.whl (243 kB)
Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)
Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)
Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Using cached rignore-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)
Using cached rpds_py-0.30.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)
Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
Using cached sentry_sdk-2.48.0-py2.py3-none-any.whl (414 kB)
Using cached supervisor-4.3.0-py2.py3-none-any.whl (320 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached typer-0.20.1-py3-none-any.whl (47 kB)
Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)
Using cached uvicorn-0.40.0-py3-none-any.whl (68 kB)
Using cached httptools-0.7.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (456 kB)
Using cached uvloop-0.22.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.8 MB)
Using cached watchfiles-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)
Using cached websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)
Using cached aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
Using cached multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)
Using cached yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)
Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
Using cached frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)
Using cached propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)
Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)
Using cached blake3-1.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)
Using cached cachetools-6.2.4-py3-none-any.whl (11 kB)
Using cached cbor2-5.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)
Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)
Using cached cupy_cuda12x-13.6.0-cp311-cp311-manylinux2014_x86_64.whl (113.0 MB)
Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)
Using cached dill-0.4.0-py3-none-any.whl (119 kB)
Using cached einops-0.8.1-py3-none-any.whl (64 kB)
Using cached ijson-3.4.0.post0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (134 kB)
Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)
Using cached loguru-0.7.3-py3-none-any.whl (61 kB)
Using cached mcp-1.25.0-py3-none-any.whl (233 kB)
Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)
Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)
Using cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)
Using cached cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)
Using cached sse_starlette-3.0.4-py3-none-any.whl (11 kB)
Using cached msgspec-0.20.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (219 kB)
Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
Using cached nvidia_ml_py-13.590.44-py3-none-any.whl (50 kB)
Using cached partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)
Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)
Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Using cached pybase64-1.4.3-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)
Using cached pycparser-2.23-py3-none-any.whl (118 kB)
Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)
Using cached scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)
Using cached sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
Using cached setproctitle-1.3.7-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)
Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)
Installing collected packages: supervisor, py-cpuinfo, nvidia-ml-py, nvidia-cusparselt-cu12, fastrlock, websockets, uvloop, urllib3, typing-inspection, triton, tqdm, tabulate, sympy, sniffio, shellingham, setproctitle, sentencepiece, safetensors, rpds-py, rignore, regex, pyzmq, pyyaml, python-multipart, python-json-logger, python-dotenv, pyjwt, pygments, pydantic-core, pycparser, pycountry, pybase64, psutil, protobuf, propcache, prometheus_client, pillow, partial-json-parser, packaging, outlines_core, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cudnn-frontend, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, multidict, msgspec, msgpack, mdurl, loguru, llvmlite, llguidance, lark, jmespath, jiter, interegular, ijson, idna, httpx-sse, httptools, hf-xet, h11, frozenlist, fastar, einops, docstring-parser, dnspython, distro, diskcache, dill, cuda-pathfinder, cloudpickle, click, charset_normalizer, certifi, cbor2, cachetools, blake3, attrs, astor, apache-tvm-ffi, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, sentry-sdk, scipy, requests, referencing, pydantic, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, httpcore, gguf, email-validator, depyf, cupy-cuda12x, cuda-bindings, cffi, anyio, aiosignal, watchfiles, tiktoken, starlette, rich, pydantic-settings, pydantic-extra-types, openai-harmony, nvidia-cusolver-cu12, lm-format-enforcer, jsonschema-specifications, huggingface-hub, httpx, cuda-python, cryptography, aiohttp, typer, torch, tokenizers, sse-starlette, rich-toolkit, prometheus-fastapi-instrumentator, openai, nvidia-cutlass-dsl, jsonschema, fastapi, anthropic, transformers, torchvision, torchaudio, ray, model-hosting-container-standards, mistral_common, mcp, flashinfer-python, fastapi-cloud-cli, fastapi-cli, xgrammar, compressed-tensors, vllm
  Attempting uninstall: nvidia-cusparselt-cu12
    Found existing installation: nvidia-cusparselt-cu12 0.6.2
    Uninstalling nvidia-cusparselt-cu12-0.6.2:
      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2
  Attempting uninstall: triton
    Found existing installation: triton 3.2.0
    Uninstalling triton-3.2.0:
      Successfully uninstalled triton-3.2.0
  Attempting uninstall: sympy
    Found existing installation: sympy 1.13.1
    Uninstalling sympy-1.13.1:
      Successfully uninstalled sympy-1.13.1
  Attempting uninstall: nvidia-nvtx-cu12
    Found existing installation: nvidia-nvtx-cu12 12.4.127
    Uninstalling nvidia-nvtx-cu12-12.4.127:
      Successfully uninstalled nvidia-nvtx-cu12-12.4.127
  Attempting uninstall: nvidia-nvjitlink-cu12
    Found existing installation: nvidia-nvjitlink-cu12 12.4.127
    Uninstalling nvidia-nvjitlink-cu12-12.4.127:
      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127
  Attempting uninstall: nvidia-nccl-cu12
    Found existing installation: nvidia-nccl-cu12 2.21.5
    Uninstalling nvidia-nccl-cu12-2.21.5:
      Successfully uninstalled nvidia-nccl-cu12-2.21.5
  Attempting uninstall: nvidia-curand-cu12
    Found existing installation: nvidia-curand-cu12 10.3.5.147
    Uninstalling nvidia-curand-cu12-10.3.5.147:
      Successfully uninstalled nvidia-curand-cu12-10.3.5.147
  Attempting uninstall: nvidia-cuda-runtime-cu12
    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127
    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127
  Attempting uninstall: nvidia-cuda-nvrtc-cu12
    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127
    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127
  Attempting uninstall: nvidia-cuda-cupti-cu12
    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127
    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:
      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127
  Attempting uninstall: nvidia-cublas-cu12
    Found existing installation: nvidia-cublas-cu12 12.4.5.8
    Uninstalling nvidia-cublas-cu12-12.4.5.8:
      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8
  Attempting uninstall: nvidia-cusparse-cu12
    Found existing installation: nvidia-cusparse-cu12 12.3.1.170
    Uninstalling nvidia-cusparse-cu12-12.3.1.170:
      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170
  Attempting uninstall: nvidia-cufft-cu12
    Found existing installation: nvidia-cufft-cu12 11.2.1.3
    Uninstalling nvidia-cufft-cu12-11.2.1.3:
      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3
  Attempting uninstall: nvidia-cudnn-cu12
    Found existing installation: nvidia-cudnn-cu12 9.1.0.70
    Uninstalling nvidia-cudnn-cu12-9.1.0.70:
      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70
  Attempting uninstall: nvidia-cusolver-cu12
    Found existing installation: nvidia-cusolver-cu12 11.6.1.9
    Uninstalling nvidia-cusolver-cu12-11.6.1.9:
      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9
  Attempting uninstall: torch
    Found existing installation: torch 2.6.0+cu124
    Uninstalling torch-2.6.0+cu124:
      Successfully uninstalled torch-2.6.0+cu124

Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-doc-0.0.4 annotated-types-0.7.0 anthropic-0.71.0 anyio-4.12.0 apache-tvm-ffi-0.1.6 astor-0.8.1 attrs-25.4.0 blake3-1.0.8 cachetools-6.2.4 cbor2-5.7.1 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 compressed-tensors-0.12.2 cryptography-46.0.3 cuda-bindings-13.1.1 cuda-pathfinder-1.3.3 cuda-python-13.1.1 cupy-cuda12x-13.6.0 depyf-0.20.0 dill-0.4.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.8.0 docstring-parser-0.17.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.127.0 fastapi-cli-0.0.16 fastapi-cloud-cli-0.7.0 fastar-0.8.0 fastrlock-0.8.3 flashinfer-python-0.5.3 frozenlist-1.8.0 gguf-0.17.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 httpx-sse-0.4.3 huggingface-hub-0.36.0 idna-3.11 ijson-3.4.0.post0 interegular-0.3.3 jiter-0.12.0 jmespath-1.0.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 lark-1.2.2 llguidance-1.3.0 llvmlite-0.44.0 lm-format-enforcer-0.11.3 loguru-0.7.3 markdown-it-py-4.0.0 mcp-1.25.0 mdurl-0.1.2 mistral_common-1.8.6 model-hosting-container-standards-0.1.12 msgpack-1.1.2 msgspec-0.20.0 multidict-6.7.0 ninja-1.13.0 numba-0.61.2 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cudnn-frontend-1.17.0 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-cutlass-dsl-4.3.4 nvidia-ml-py-13.590.44 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 openai-2.14.0 openai-harmony-0.0.8 opencv-python-headless-4.12.0.88 outlines_core-0.2.11 packaging-25.0 partial-json-parser-0.2.1.1.post7 pillow-12.0.0 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.23.1 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 py-cpuinfo-9.0.0 pybase64-1.4.3 pycountry-24.6.1 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-extra-types-2.10.6 pydantic-settings-2.12.0 pygments-2.19.2 pyjwt-2.10.1 python-dotenv-1.2.1 python-json-logger-4.0.0 python-multipart-0.0.21 pyyaml-6.0.3 pyzmq-27.1.0 ray-2.53.0 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 rich-14.2.0 rich-toolkit-0.17.1 rignore-0.7.6 rpds-py-0.30.0 safetensors-0.7.0 scipy-1.16.3 sentencepiece-0.2.1 sentry-sdk-2.48.0 setproctitle-1.3.7 shellingham-1.5.4 sniffio-1.3.1 sse-starlette-3.0.4 starlette-0.50.0 supervisor-4.3.0 sympy-1.14.0 tabulate-0.9.0 tiktoken-0.12.0 tokenizers-0.22.1 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 tqdm-4.67.1 transformers-4.57.3 triton-3.5.0 typer-0.20.1 typing-inspection-0.4.2 urllib3-2.6.2 uvicorn-0.40.0 uvloop-0.22.1 vllm-0.13.0 watchfiles-1.1.1 websockets-15.0.1 xgrammar-0.1.27 yarl-1.22.0
================================================================================
PROMPT INJECTION RECOVERY EXPERIMENT
================================================================================

[1/6] Loading prompts from markdown files...
  Loaded 2 question format prompts (using top 2):
    1. chain_of_thought
    2. conversational_tutor
  Loaded 4 injection texts (using top 4):
    1. authority_claim
    2. fake_completion
    3. system_override
    4. topic_change

Model: /home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B
Questions: 10
Prompts (K): 2
Injections (M): 4
Total combinations: 80
================================================================================

[2/6] Loading model with vLLM...
INFO 12-22 11:38:32 [utils.py:253] non-default args: {'trust_remote_code': True, 'dtype': 'float16', 'disable_log_stats': True, 'model': '/home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B'}
INFO 12-22 11:38:32 [model.py:514] Resolved architecture: Qwen2ForCausalLM
WARNING 12-22 11:38:32 [model.py:2005] Casting torch.bfloat16 to torch.float16.
INFO 12-22 11:38:32 [model.py:1661] Using max model len 131072
INFO 12-22 11:38:36 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:38:37 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='/home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B', speculative_config=None, tokenizer='/home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=/home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:38:40 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://132.67.247.130:51681 backend=nccl
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:38:40 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:38:45 [gpu_model_runner.py:3562] Starting to load model /home/ADV_2526a/evyataroren/inter_2025/models/DS-qwen-7B/DeepSeek-R1-Distill-Qwen-7B...
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:38:49 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:19 [default_loader.py:308] Loading weights took 149.87 seconds
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:20 [gpu_model_runner.py:3659] Model loading took 14.2717 GiB memory and 153.570274 seconds
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:31 [backends.py:643] Using cache directory: /a/home/cc/students/cs/evyataroren/.cache/vllm/torch_compile_cache/4f3758a5a9/rank_0_0/backbone for vLLM's torch.compile
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:31 [backends.py:703] Dynamo bytecode transform time: 11.41 s
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:35 [backends.py:261] Cache the graph of compile range (1, 8192) for later use
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:37 [backends.py:278] Compiling a graph for compile range (1, 8192) takes 3.39 s
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:37 [monitor.py:34] torch.compile takes 14.81 s in total
[0;36m(EngineCore_DP0 pid=1292519)[0;0m INFO 12-22 11:41:40 [gpu_worker.py:375] Available KV cache memory: 5.55 GiB
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     super().__init__(
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 109, in __init__
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     check_enough_kv_cache_memory(
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]   File "/home/ADV_2526a/evyataroren/inter_2025/.miniconda3/envs/inter25_vllm/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py", line 710, in check_enough_kv_cache_memory
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866]     raise ValueError(
[0;36m(EngineCore_DP0 pid=1292519)[0;0m ERROR 12-22 11:41:40 [core.py:866] ValueError: To serve at least one request with the models's max seq len (131072), (7.00 GiB KV cache is needed, which is larger than the available KV cache memory (5.55 GiB). Based on the available memory, the estimated maximum model length is 103952. Try increasing `gpu_memory_utilization` or decreasing `max_model_len` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
