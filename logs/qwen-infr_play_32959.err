/specific/scratches/parallel/evyataroren-2025-12-31/inter_2025/.miniconda3/envs/inter2025_vllm/lib/python3.11/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:56<01:56, 116.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:23<00:00, 98.91s/it] Loading checkpoint shards: 100%|██████████| 2/2 [03:23<00:00, 101.58s/it]
slurmstepd: error: *** JOB 32959 ON n-805 CANCELLED AT 2026-01-11T11:00:37 ***
